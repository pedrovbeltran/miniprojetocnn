{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini -projeto - CNN\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Este diário é referente ao mini-projeto da disciplina de Redes Neurais onde uma RNC (Rede Neural Convolucional ou, do inglês *CNN* - *Convolutional Neural Network*) será usada para reconhecimento de dígitos manuscritos seguindo o roteiro proposto no capíulo 6 do livro [*Neural networks and deep learning*](http://neuralnetworksanddeeplearning.com/chap6.html) escrito por Michael Nielsen com algumas modificações que visam a objetividade do projeto e ainda devido à solicitação do prof da disciplina, será implementada uma técnica que o livro cita como *early stopping*, que consiste na parada automática do programa quando não há melhoramento significativo da acurácia do programa.\n",
    "\n",
    "Para essa técnica usaremos o conjunto de validação para trabalhar\n",
    "\n",
    "## Equipe:\n",
    "\n",
    "**Pedro Beltran:** [@pedrovbeltran](https://github.com/pedrovbeltran)\n",
    "\n",
    "**Luana Silva: ** [@luana-leticia](https://gitbuh.com/luana-leticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dia 1:\n",
    "\n",
    "Após realizadas as modificações, começaremos de maneira análoga ao primeiro mini-projeto estabelecendo um valor pequeno para o parâmetro *no improvement in* do algortimo *early stopping*, tal como 5 épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training network after 24 epochs.\n",
      "Best test accuracy of 97.66% obtained at iteration 114999\n",
      "Best validation accuracy of 97.80% obtained at iteration 94999\n"
     ]
    }
   ],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
    "training_data, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "net = Network([\n",
    "        FullyConnectedLayer(n_in=784, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "test_accuracy = net.SGD(training_data, 5, mini_batch_size, 0.1, \n",
    "                        validation_data, test_data, monitor_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para facilitar o plot depois salvaremos o que fizemos de forma simples em um arquivo. Faremos isto apenas no primeiro e no último teste por questões de praticidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open(\"saved_accuracy_test1.json\", \"w\")\n",
    "json.dump(test_accuracy, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dia 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para pegar uma base apenas fizemos um teste rápido com uma rede totalmente conectada com uma camada oculta de 100 neurônios para termos uma base do quanto o programa irá melhorar. Agora iremos inserir uma camada convolucional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training network after 25 epochs.\n",
      "Best test accuracy of 98.65% obtained at iteration 124999\n",
      "Best validation accuracy of 98.59% obtained at iteration 99999\n"
     ]
    }
   ],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
    "training_data, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        FullyConnectedLayer(n_in=20*12*12, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "test_accuracy = net.SGD(training_data, 5, mini_batch_size, 0.1, \n",
    "                        validation_data, test_data, monitor_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testando agora com mais uma camada convolucional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training network after 34 epochs.\n",
      "Best test accuracy of 99.05% obtained at iteration 154999\n",
      "Best validation accuracy of 98.97% obtained at iteration 144999\n"
     ]
    }
   ],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
    "training_data, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2)),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "test_accuracy = net.SGD(training_data, 5, mini_batch_size, 0.1, \n",
    "                        validation_data, test_data, monitor_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora tentaremos obter uma melhora outra vez com $\\eta = 0.03$, com regularização L2 ($\\lambda = 0.1$) e mudando a função de ativação das unidades para a ReLU (do inglês *Rectified Linear Unit*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training network after 25 epochs.\n",
      "Best test accuracy of 98.92% obtained at iteration 99999\n",
      "Best validation accuracy of 99.01% obtained at iteration 99999\n"
     ]
    }
   ],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
    "training_data, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "from network3 import ReLU\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(training_data, 5, mini_batch_size, 0.03, \n",
    "            validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtivemos uma pequena melhora na acurácia no conjunto de validação mas não na do conjunto de teste, mas ainda assim demoramos menos épocas no treinamento e faremos outro teste, dessa vez usando um conjunto de treinamento expandido tal como o roteiro proposto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training network after 18 epochs.\n",
      "Best test accuracy of 99.25% obtained at iteration 324999\n",
      "Best validation accuracy of 99.30% obtained at iteration 324999\n"
     ]
    }
   ],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
    "training_data, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "from network3 import ReLU\n",
    "expanded_training_data, _, _ = network3.load_data_shared(\n",
    "        \"/home/pedro/mnist_expanded.pkl.gz\") # My particular path to the file\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(expanded_training_data, 5, mini_batch_size, 0.03, \n",
    "        validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mais uma vez obtivemos melhores resultados, apesar de ter aumentado o tempo do processo de aprendizado devido ao conjunto de treinamento aumentado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora faremos o teste usando mais uma camada completamente conectada com 100 neurônios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training network after 16 epochs.\n",
      "Best test accuracy of 99.23% obtained at iteration 374999\n",
      "Best validation accuracy of 99.32% obtained at iteration 274999\n"
     ]
    }
   ],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
    "_, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "from network3 import ReLU\n",
    "expanded_training_data, _, _ = network3.load_data_shared(\n",
    "        \"/home/pedro/mnist_expanded.pkl.gz\") # My particular path to the file\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=40*4*4, n_out=100, activation_fn=ReLU),\n",
    "        FullyConnectedLayer(n_in=100, n_out=100, activation_fn=ReLU),\n",
    "        SoftmaxLayer(n_in=100, n_out=10)], mini_batch_size)\n",
    "net.SGD(expanded_training_data, 5, mini_batch_size, 0.03, \n",
    "            validation_data, test_data, lmbda=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, como último teste teremos o aumento das camadas intermediárias para 1000 neurônios e implementaremos a técnica *Dropout*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network3\n",
    "from network3 import Network\n",
    "from network3 import ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer\n",
    "_, validation_data, test_data = network3.load_data_shared()\n",
    "mini_batch_size = 10\n",
    "from network3 import ReLU\n",
    "expanded_training_data, _, _ = network3.load_data_shared(\n",
    "        \"/home/pedro/mnist_expanded.pkl.gz\") # My particular path to the file\n",
    "net = Network([\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 1, 28, 28), \n",
    "                      filter_shape=(20, 1, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        ConvPoolLayer(image_shape=(mini_batch_size, 20, 12, 12), \n",
    "                      filter_shape=(40, 20, 5, 5), \n",
    "                      poolsize=(2, 2), \n",
    "                      activation_fn=ReLU),\n",
    "        FullyConnectedLayer(\n",
    "            n_in=40*4*4, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n",
    "        FullyConnectedLayer(\n",
    "            n_in=1000, n_out=1000, activation_fn=ReLU, p_dropout=0.5),\n",
    "        SoftmaxLayer(n_in=1000, n_out=10, p_dropout=0.5)], \n",
    "        mini_batch_size)\n",
    "test_accuracy = net.SGD(expanded_training_data, 5, mini_batch_size, 0.03, \n",
    "                        validation_data, test_data, monitor_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
